'''
USAGE NOTES SCRIPT
- run in (standalone version of) psychoPy v 2025.1.1
- test: psychopy & psychopy backend should be callable --> critical TODO test on MPI Linux
- set prefs.hardware['audioDevice'] to the name of your local audio device
- if necessary change window size for screen presentation
- if necessary change sampling rate for audio (var sample_rate)
- if necessary: change key_pos (should be v, z, u, i, l keys with the right hand) --> here, I am using a US keyboard layout
- if necessary: adjust pahandle to your machine (should be fine though)
- if desired: change implementation of harmonics
- run generate_task_sequences.py first to generate sequences, then run this experiment from the same directory (now containing a trial_lists directory)
- input: participant nr. as specified during generate_task_sequences.py and session number as 01, 02, 03, 04, 05, or 06
'''

'''
TASK
- identify the deviant at the end of each trial of eight tones (as soon as the fixation cross turns blue, you can answer)
- answer within 1.5 s, otherwise too slow
- keypresses:
        - v = dev 3
        - z = dev 4
        - u = dev 5
        - i = dev 6
        - l = dev 7
- if a key was pressed during response window: indicate how confident you are in your response using the same keys
- press space to continue after breaks between runs and to end the experiment of the last screen
- press esc to exit anytime
'''

'''
NOTES on RT Implementation:
- for behavioral experiment rely on ptb.GetSecs()
--> might need to rethink for scanner --> see other version of script
--> big TODO: think of testing key precision of different implementations & scanner hardware delay
'''

#---- set preferences first --> ATTENTION: manually use ptb backend for keyboard later on anyways on Mac!
from psychopy import prefs
prefs.general['version'] = '2025.1.1'
prefs.hardware['keyboard'] = 'ptb'
prefs.hardware['audioLib'] = 'ptb'
prefs.hardware['audioLatencyMode'] = '4' # could also use 4 but then no fallback in case of small deviation
#prefs.hardware['audioDevice'] = 'Externe Kopfhörer' # cable headphones
#prefs.hardware['audioDevice'] = 'Mac mini-Lautsprecher' # mac mini speakers
prefs.hardware['audioDevice'] = 'Speakers (Realtek HD Audio output)'

#---- check psychopy version
from psychopy import useVersion
#useVersion('2025.1.1')

import psychopy
print(f"Running PsychoPy {psychopy.__version__}")

from psychopy import sound
from psychtoolbox import PsychPortAudio

#---- imports
import psychtoolbox as ptb
from psychtoolbox import audio
from psychtoolbox import PsychPortAudio
PsychPortAudio('Close')

from psychopy import sound
import sounddevice as sd
from psychopy.sound import backend_ptb as ptb_back
from psychopy import core
from psychopy import visual
from psychopy.hardware import keyboard
from psychopy import gui
from psychopy import monitors

import pandas as pd
import numpy as np
import soundfile as sf
from datetime import date
import os

#---- create logfile directory if not already existing
os.makedirs('logfiles_behavioral/', exist_ok=True)

#---- open GUI to enter participant information
expName = 'AuditPrePro'
expInfo = {'participant':'', 'session':''} # enter participant and session info as defined in generate_task_sequences.py


dlg = gui.DlgFromDict(dictionary=expInfo, sortKeys=False,title=expName)
if dlg.OK == False:
    core.quit()
expInfo['date'] = date.today()

participant = expInfo['participant']
session = expInfo['session']

date = date.today()
date = date.strftime("%Y-%m-%d")

if session == 'training':
    trial_list_dir = 'trial_lists_training/' # set directory for relevant trial list files (generated by generate_task_sequences.py)
else:
    trial_list_dir = 'trial_lists/'


#---- open a screen and test if refresh rate can be measured
mon = monitors.Monitor('tempMonitor')  # name can be anything
mon.setSizePix([3840, 2160])  

win = visual.Window(
    size=(3840, 2160),
    fullscr=True,
    screen=1,
    units='pix',
    color= 0,
    monitor = mon
)

win.mouseVisible = False

refresh_rate = win.getActualFrameRate(
    nIdentical=20, nMaxFrames=200, nWarmUpFrames=10, threshold=1
)

if refresh_rate:
    print(f"Refresh rate: {refresh_rate:.2f} Hz")
else:
    print("Could not measure refresh rate.")
    
message = visual.TextStim(win, text='Starte Experiment ...', wrapWidth=2000)
message.height = 100
message.draw()
win.flip()

#---- define variables to record
onset_sound = []
onset_tones = []

duration_sound = [] # based on theoretical duration
duration_sound_getsecs = [] # based on getsecs

offset_trial = [] # based on theroretical duretion

offset_sound = [] # based on theoretical duration
offset_sound_getsecs = [] # based on getsecs

onset_iti_list = [] # based on theoretical duration
onset_iti_list_getsecs = [] # based on getsecs

offset_iti_list = [] # based on theoretical duration
offset_iti_list_getsecs = [] # based on getsecs

ITI_list = [] # theoretical ITIs

tau = []

frequency = [] # tone frequency in Hz
lim_std = []
lim_dev = []

rule = [] # rule
dpos = [] # deviant positions
tone_type = [] # std or deviant

runs = []
trial_nr = []

# initialize all keyboards
escape_kb = keyboard.Keyboard(backend='ptb') # set keyboard that can be used to stop the experiment at any point
escape_kb.waitKeys(maxWait=1) 

trigger_kb = keyboard.Keyboard(backend = 'ptb') # trigger kb
trigger_kb.waitKeys(maxWait=1)  

response_kb = keyboard.Keyboard(backend = 'ptb') # response kb
response_kb.waitKeys(maxWait=1)  

slider_kb = keyboard.Keyboard(backend = 'ptb') # response kb
slider_kb.waitKeys(maxWait=1)  

# create slider + text for confidence ratings
slider = visual.Slider(
    win=win,
    pos=(0, 0),
    size=(1600, 100),
    labels=["1\nsehr\nunsicher", "2", "3", "4", "5\nsehr\nsicher"],
    ticks=[0, 25, 50, 75, 100], 
    style='rating',
    color='DarkSlateBlue',
    markerColor='Red'
)

#---- functions to generate soundwaves for the sounds and ISI/ITI
def generate_timbre_waveform(frequency = 1450.0, harmonics = [(1, 1.0), (2, 0.5), (3, 0.33), (4, 0.25), (5, 0.2)], duration = 0.1, sample_rate= 48000, ramp_time = 0.01, hanning = True):

    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)
    waveform = np.zeros_like(t)

    for multiple, amplitude in harmonics:
        waveform += amplitude * np.sin(2 * np.pi * frequency * multiple * t)

    waveform /= np.max(np.abs(waveform))
    
    if hanning == False:
        ramp_samples = int(sample_rate * ramp_time)
        ramp = np.linspace(0, 1, ramp_samples)
        envelope = np.ones_like(waveform)
        envelope[:ramp_samples] *= ramp
        envelope[-ramp_samples:] *= ramp[::-1]
    
    elif hanning == True: 
        ramp_samples = int(sample_rate * ramp_time)
        full_window = np.hanning(2 * ramp_samples)
        ramp_in = full_window[:ramp_samples]
        ramp_out = full_window[ramp_samples:]

        envelope = np.ones_like(waveform)
        envelope[:ramp_samples] *= ramp_in
        envelope[-ramp_samples:] *= ramp_out

    return waveform * envelope * 0.3
    

def generate_isi(duration = 0.65, sample_rate = 48000):
    
    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)
    waveform_isi = np.zeros_like(t)

    return waveform_isi

#---- define important variables

# possible implementation of different harmonics
harmonics_dict =  {
    "pure": [(1.0, 1.0)],
    "minor third": [(1, 1.0), (6/5, 0.5)], # 1/n
    "major third": [(1, 1.0), (5/4, 0.5)], # 1/n
    "perfect fourth": [(1, 1.0), (4/3, 0.5)], # 1/n
    "perfect fifth": [(1, 1.0), (3/2, 0.5)], # 1/n
    "minor sixth": [(1, 1.0), (8/5, 0.5)], # 1/n
    "major sixth": [(1, 1.0), (5/3, 0.5)], # 1/n
    "octave": [(1, 1.0), (2, 0.5)], # 1/n
    "1/n": [(n, 1/n) for n in range(1, 6)], # pure 1/n
    "1/n^2": [(n, 1/(n**2)) for n in range(1, 6)],
    "e^(-0.5(n-1))": [(n, np.exp(-0.5*(n - 1))) for n in range(1, 6)],
    "odd 1/n": [(n, 1/n) for n in range(1, 10, 2)]
}

harmonics = harmonics_dict['1/n'] # choose implementation of harmonics

sample_rate = 48000 # adjust to final device used!
ramp_time = 0.01 # ramp time for on/off ramps
stim_dur = 0.1 # total stmulus duration incl. on/off ramps
isi_dur = 0.65 # inter-stimulus-interval

response_window = 1.5 # --> too short? --> TODO pilot
trial_duration = (8*stim_dur) + (7*isi_dur) # trial duration
key_pos = ['v','y','u','i','l'] # response keys
key_pos_slider = ['1','2','3','4','5']
feedback_duration = 2 # feedback duration

#---- read in the pre-created trial lists
trials = pd.read_csv(f'{trial_list_dir}sub-{participant}/sub-{participant}_ses-{session}_trials.csv')
trials['dpos'] = trials['dpos'].fillna(0).astype(int)
n_trials = len(trials)/8

rts_getsecs = [None]*int(n_trials) # RT based on ptb.getSecs()
rts_slider_getsecs = [None]*int(n_trials) # RT for confidence slider based on ptb.getSecs()
keys_pressed = [None]*int(n_trials) # pressed key
performance = [None]*int(n_trials) # correct?
confidence = [None]*int(n_trials) # confidence ratings

#---- more important variables
if session == 'training':
    run_step = len(trials)
    run_indices = [(i * run_step, (i + 1) * run_step) for i in range(1)]
    #print(run_indices)
else:
    run_step = len(trials) // 4
    run_indices = [(i * run_step, (i + 1) * run_step) for i in range(4)]
    #print(run_indices)

sound_list = []
len_waveform = []
buffer_handles = []

#---- open audio port
pahandle = PsychPortAudio('Open', [], 1, 4, sample_rate, 1) # for mac mini Jasmin --> adjust to final machine!

#---- load experiment: create all trials in advance from previously generated trial_list
for i in range(0, len(trials), 8):
    
    message = visual.TextStim(win, text='Lade Stimuli ...', wrapWidth=2000)
    message.height = 100
    message.draw()
    win.flip()
    
    waveform = []
    oddball_trial = trials['frequency'][i:i + 8]
    
    dpos_trial = trials['dpos'][i:i+8]
    dposy = dpos_trial.iloc[0]
    dposy = int(dposy)
    dpos.append(dposy)
    
    run_trial = trials['run_n'][i:i+8]
    runy = run_trial.iloc[0]
    runs.append(runy)
    
    rule_trial = trials['rule'][i:i+8]
    ruly = rule_trial.iloc[0]
    rule.append(ruly)
    
    tones_trial = np.zeros(8)
    if dposy != 0:
        tones_trial[dposy] = 1
    tone_type.append(tones_trial.astype(int))
    
    trial_trial = trials['trial_n'][i:i+8]
    trialy = trial_trial.iloc[0]
    trial_nr.append(trialy)
    
    tau_std_trial = trials['tau_std'][i:i+8]
    tauy = tau_std_trial.iloc[0]
    tau.append(tauy)
    
    lim_std_trial = trials['lim_std'][i:i+8]
    lim_stdy = lim_std_trial.iloc[0]
    lim_std.append(lim_stdy)
    
    lim_dev_trial = trials['lim_dev'][i:i+8]
    lim_devy = lim_dev_trial.iloc[0]
    lim_dev.append(lim_devy)
            
    ITI = trials['ITI'][i]
    ITI_list.append(ITI)
        
    tone_count = 0
    
    for s in oddball_trial:
        tone_count += 1
        frequency.append(round(s,2))
        wave = generate_timbre_waveform(round(s,2), harmonics, stim_dur, sample_rate, ramp_time)
        waveform.append(wave)
        
        if tone_count < 8:
            isi = generate_isi(isi_dur, sample_rate)
            waveform.append(isi)
        elif tone_count == 8:
            iti_wave = generate_isi(ITI, sample_rate)
            waveform.append(iti_wave)
        
    waveform = np.concatenate(waveform)
    len_waveform.append(len(waveform))
    
    waveform = waveform.astype(np.float32)
    buffer_handle = PsychPortAudio('CreateBuffer', [], waveform)
    buffer_handles.append(buffer_handle)

#---- wait for space press to start
message = visual.TextStim(win, text='Drücke die Leertaste, um zu starten.', wrapWidth=2000)
message.height = 100
message.draw()
win.flip()

trigger_list = ['space'] # ['5'] for 7T
trigger_times = []
n_triggers_to_wait = 1 # how many kay presses to wait for

for t in range(n_triggers_to_wait): # start on the first space press for behavioral experiment
    trigger_keys = trigger_kb.waitKeys(keyList=trigger_list, waitRelease=False)
  
#---- show fixation cross
message.text = ' '
message.height = 100
message.pos = (0, 0)
message.draw()
win.flip()

question = visual.TextStim(win, text='Wie sicher bist du dir?', wrapWidth=2000)
question.height = 100
question.pos = (0, 250)

prompt = visual.TextStim(win, text='bitte jetzt antworten', wrapWidth=2000)
prompt.height = 100
prompt.pos = (0, 0)

feed = visual.TextStim(win, text='', wrapWidth=2500)
feed.color = (0, 0, 0)
feed.height = 100
feed.pos = (0, 0)

#---- play oddball sequences and record logfiles separately for each run
for i in range(0, int(n_trials) + 1):
      
    # if at the end, append last run number
    if i == n_trials:
        runs.append(5)
    
    # whenever run changes:
    if i > 0 and (runs[i] != runs[i-1] or i == n_trials):
        start_wait = ptb.GetSecs()
        
        if i < n_trials:
            trial_run = run_indices[runs[i-1]]
            trial_run_slow = (np.array(trial_run)/8).astype(int)
        if i == n_trials:
            trial_run = run_indices[runs[i-2]]
            trial_run_slow = (np.array(trial_run)/8).astype(int)                

        # compute accuracy for full run to present to participant
        accuracy_run = ((len(np.where(np.array(performance[trial_run_slow[0]:trial_run_slow[1]]) == 1)[0]) + len(np.where(np.array(performance[trial_run_slow[0]:trial_run_slow[1]]) == 4)[0]))/len(performance[trial_run_slow[0]:trial_run_slow[1]]))*100
        message.text = f"% korrekte Antworten in diesem Durchgang: {accuracy_run: .2f}\n\n\nKurze Pause!\n\n\nWeiter geht's mit der Leertaste"
        message.draw()
        win.flip()
        
        # create datafile for previous run
        data = []
        
        # write datafile (TODO: make this more BIDS-like & remove unnecessary stuff!)
        data = pd.DataFrame({
            'onset': np.repeat(onset_sound[trial_run_slow[0]:trial_run_slow[1]],8), # onset sound sequence (based on PsychPortAudio)
            'onset_tone': np.concatenate(onset_tones)[trial_run[0]:trial_run[1]], # onset of each tone based on theoretical duration and isi
            'duration': np.repeat(duration_sound[trial_run_slow[0]:trial_run_slow[1]],8), # theooretical duration sound sequence 
            'duration_getsecs': np.repeat(duration_sound_getsecs[trial_run_slow[0]:trial_run_slow[1]],8), # duration based on getsecs()
            'offset_trial': np.repeat(offset_trial[trial_run_slow[0]:trial_run_slow[1]],8), # measured based on PsychPortAudio
            'offset_sound': np.repeat(offset_sound[trial_run_slow[0]:trial_run_slow[1]],8), # based on theoretical
            'offset_sound_getsecs': np.repeat(offset_sound_getsecs[trial_run_slow[0]:trial_run_slow[1]],8), # based on getsecs()
            'onset_iti': np.repeat(onset_iti_list[trial_run_slow[0]:trial_run_slow[1]],8), # based on theoretical duration
            'onset_iti_getsecs': np.repeat(onset_iti_list_getsecs[trial_run_slow[0]:trial_run_slow[1]],8), # based on getsecs()
            'offset_iti': np.repeat(offset_iti_list[trial_run_slow[0]:trial_run_slow[1]],8), # based on theoretical duration
            'offset_iti_getsecs': np.repeat(offset_iti_list_getsecs[trial_run_slow[0]:trial_run_slow[1]],8), # based on getsecs()
            'ITI': np.repeat(ITI_list,8)[trial_run[0]:trial_run[1]], # theoretical ITI
            'rt_getsecs': np.repeat(rts_getsecs[trial_run_slow[0]:trial_run_slow[1]],8), # response time based on getsecs
            'rt_slider_getsecs': np.repeat(rts_slider_getsecs[trial_run_slow[0]:trial_run_slow[1]],8), # response time for slider based on getsecs
            'tau_std': np.repeat(tau,8)[trial_run[0]:trial_run[1]], # tau std
            'frequency': frequency[trial_run[0]:trial_run[1]], # sound frequency (base)
            'lim_std': np.repeat(lim_std,8)[trial_run[0]:trial_run[1]], # mu std
            'lim_dev': np.repeat(lim_dev,8)[trial_run[0]:trial_run[1]], # mu dev
            'key_pressed': np.repeat(keys_pressed[trial_run_slow[0]:trial_run_slow[1]],8), # pressed key
            'correct': np.repeat(performance[trial_run_slow[0]:trial_run_slow[1]],8), # key press correct?
            'confidence': np.repeat(confidence[trial_run_slow[0]:trial_run_slow[1]],8), # confidence
            'rule': np.repeat(rule,8)[trial_run[0]:trial_run[1]], # rule no
            'dpos': np.repeat(dpos,8)[trial_run[0]:trial_run[1]], # deviant position
            'trial_type': np.concatenate(tone_type)[trial_run[0]:trial_run[1]], # standard or deviant?
            'runs': np.repeat(runs,8)[trial_run[0]:trial_run[1]], # run no
            'trial_no': np.repeat(trial_nr,8)[trial_run[0]:trial_run[1]], # trial no
        })
        
        if runs[i] == 5 and session != 'training':
             data.to_csv(f'logfiles_behavioral/sub-{participant}-ses-{session}-run{runs[i]-1}-events_{date}.tsv', sep='\t', index=False)
             break
        if runs[i] == 5 and session == 'training':
             data.to_csv(f'logfiles_behavioral/sub-{participant}-ses-{session}-events_{date}.tsv', sep='\t', index=False)
             break
        else:
            data.to_csv(f'logfiles_behavioral/sub-{participant}-ses-{session}-run{runs[i]}-events_{date}.tsv', sep='\t', index=False)
        
            # wait for space key press to initialize next run
            pause_kb = keyboard.Keyboard(backend = 'ptb')
            pause_keys = pause_kb.waitKeys(keyList=['space'], waitRelease=False)
            message.text = '+'
            message.draw()
            win.flip()
    
    phase ='stimulus'
    key_pressed = False
    slider_key_pressed = False
    feedback_recorded = False
    slider_rating = None
    slider_start = None
    feedback_start = None
    response_start = None
    key_name = None
    key_rt = None
    slider_rt = None
    slider_end = None
    slider_time = None
    max_slider_time = 2
    slider.reset()

    feed.color = (1, 1, 1)
    feed.text = 'empty'

    # play audio sequences from buffer
    PsychPortAudio('UseSchedule', pahandle, 1)  # 1 = replace current schedule
    PsychPortAudio('AddToSchedule', pahandle, buffer_handles[i])
    onset = PsychPortAudio('Start', pahandle, 1, 0, 1) # measure onset trial based on PsychPortAudio
    
    response_kb.clearEvents()  # clear any leftover keys
    slider_kb.clearEvents()  # clear any leftover keys

    while True:
        
        elapsed = ptb.GetSecs() 
        
        # make experiment closable by Esc key press
        if 'escape' in [k.name for k in escape_kb.getKeys(['escape'], waitRelease=False)]:
            core.quit(); sys.exit()
        
        elif elapsed - onset <= (len_waveform[i] / sample_rate):

            if phase == 'stimulus':
                
                if elapsed-onset <= trial_duration:
                   message.text = '+'
                   message.color = (1, 1, 1)
                   message.pos = (0, 0)
                   offset_stimulus = elapsed
               
                else:
                    phase = 'response'
                    response_start = ptb.GetSecs()
                    onset_iti = ptb.GetSecs()
                  
            elif phase == 'response':
                
                if key_pressed == False:
                    
                    response_keys = response_kb.getKeys(key_pos, waitRelease=False)

                    if response_keys and not key_pressed:
                        key_pressed = True
                        key_name = response_keys[0].name
                        key_rt = ptb.GetSecs() - response_start

                        if not feedback_recorded:
                
                            if dpos[i] != 0 and key_pressed:
                                correct_key = dpos[i] - 2
                                key_posy = key_pos.index(key_name)
                                
                                if correct_key == key_posy:
                                    performance[i] = 1
                                    feed.color = (0, 1, 0)
                                    feed.text = "richtig\n\nabweichender Ton in der angegebenen Position"
                                    feedback_recorded = True
                                    
                                else:
                                    performance[i] = 0
                                    feed.color = (1, 0, 0)
                                    feed.text = "falsch\n\nabweichender Ton in einer anderen Position"
                                    feedback_recorded = True

                            elif dpos[i] != 0 and not key_pressed:
                                performance[i] = 3
                                feed.color = (1, 0, 0)
                                feed.text = "falsch\n\nabweichender Ton vorhanden"
                                feedback_recorded = True        
                            
                            elif dpos[i] == 0 and not key_pressed:
                                performance[i] = 4
                                feed.color = (0, 1, 0)
                                feed.text = "richtig\n\nkein abweichender Ton vorhanden"
                                feedback_recorded = True

                            elif dpos[i] == 0 and key_pressed:
                                performance[i] = 5
                                feed.color = (1, 0, 0)
                                feed.text = "falsch:\n\nkein abweichender Ton vorhanden"
                                feedback_recorded = True
                                
                        phase = 'slider'
                        slider_start = ptb.GetSecs()
                    
                    elif elapsed-onset > trial_duration + response_window:

                        if not feedback_recorded:
                
                            if dpos[i] != 0 and key_pressed:
                                correct_key = dpos[i] - 2
                                key_posy = key_pos.index(key_name)
                                
                                if correct_key == key_posy:
                                    performance[i] = 1
                                    feed.color = (0, 1, 0)
                                    feed.text = "richtig:\n\nabweichender Ton in der angegebenen Position"
                                    feedback_recorded = True
                                    
                                else:
                                    performance[i] = 0
                                    feed.color = (1, 0, 0)
                                    feed.text = "falsch:\n\nabweichender Ton in einer anderen Position"
                                    feedback_recorded = True
                            
                            elif dpos[i] != 0 and not key_pressed:
                                performance[i] = 3
                                feed.color = (1, 0, 0)
                                feed.text = "falsch:\n\nabweichender Ton vorhanden"
                                feedback_recorded = True 
                            
                            elif dpos[i] == 0 and not key_pressed:
                                performance[i] = 4
                                feed.color = (0, 1, 0)
                                feed.text = "richtig:\n\nkein abweichender Ton vorhanden"
                                feedback_recorded = True
                                
                            elif dpos[i] == 0 and key_pressed:
                                performance[i] = 5
                                feed.color = (1, 0, 0)
                                feed.text = "falsch:\n\nkein abweichender Ton vorhanden"
                                feedback_recorded = True

                        phase = 'slider'
                        slider_start = ptb.GetSecs()

            elif phase == 'slider':
            
                slider_time = ptb.GetSecs() - slider_start
                slider_keys = slider_kb.getKeys(key_pos_slider, waitRelease=False)
                key_map = ['1', '2', '3', '4', '5']

                if not slider_key_pressed and (slider_keys or slider_time > max_slider_time):

                    if slider_keys:
                        slider_key_pressed = True
                        slider_rating = key_map.index(slider_keys[0].name) + 1
                        confidence[i] = slider_rating
                        slider_rt = ptb.GetSecs() - slider_start
                    else:
                        confidence[i] = None

                    slider_end = ptb.GetSecs()
                    slider_time_final = slider_end - slider_start

                    phase = 'feedback'
                    feedback_start = ptb.GetSecs()

            elif phase == 'feedback':       

                if ptb.GetSecs() - feedback_start <= feedback_duration:
                    feed.color = feed.color
                    feed.text = feed.text
                else:
                    phase = 'ITI' 

            elif phase == 'ITI':
                
                message.color = (1, 1, 1)
                message.text = '+'
                message.pos = (0, 0)        

            # safety against losing feedback in frame drop or small timing variance on slider
            if phase != 'feedback' and phase != 'ITI' and slider_time is not None and slider_time > max_slider_time:
                phase = 'feedback'
                feedback_start = ptb.GetSecs()
                        
            if phase == 'stimulus':
                message.draw()
            elif phase == 'ITI':
                message.draw()
            elif phase == 'feedback':
                feed.draw()    
            elif phase == 'response':
                prompt.draw()    
            elif phase == 'slider':
                question.draw()
                slider.draw()
            
            win.flip()
                    
        elif elapsed - onset > (len_waveform[i] / sample_rate):
            offset_iti = ptb.GetSecs()
            break
    
    # record come timing variables --> finalize
    offset = PsychPortAudio('Stop', pahandle, 1) # offset measured by PsychPortAudio
    offset_trial.append(offset[-1])
    onset_sound.append(onset)
    single_onsets = [onset + i * (stim_dur + isi_dur) for i in range(8)]
    onset_tones.append(single_onsets) # theoretical onsets based on measured trial start
    duration_sound.append(trial_duration) # theoretical trial duration
    offset_sound.append(onset + trial_duration)
    offset_sound_getsecs.append(offset_stimulus) # based on getsecs
    duration_sound_getsecs.append(offset_stimulus-onset) # based on getsecs
    onset_iti_list_getsecs.append(onset_iti) # based on getsecs
    offset_iti_list_getsecs.append(offset_iti)
    onset_iti_list.append(onset + trial_duration) # theoretical based on measured onset + known duration
    offset_iti_list.append(onset + trial_duration + ITI_list[i]) # theoretical based on measured onset + known durations
    
    if key_pressed == True:
        keys_pressed[i] = key_name
        rts_getsecs[i] = key_rt
    else:
        keys_pressed[i] = None
        rts_getsecs[i] = None  

    if slider_key_pressed == True:
        rts_slider_getsecs[i] = slider_rt
    else:
        rts_slider_getsecs[i] = None   

#---- display overall performance and wait for end (5 s wait, then space press ends the experiment)
accuracy = ((len(np.where(np.array(performance) == 1)[0]) + len(np.where(np.array(performance) == 4)[0]))/len(performance))*100
now = ptb.GetSecs()

if session != 'training':
    message.text = f"% korrekte Antworten in diesem Durchgang: {accuracy_run: .2f}\n\n\n% korrekte Antworten insgesamt: {accuracy: .2f}\n\n\nEnde des Experiments, bitte gib der Versuchsleitung Bescheid!"
if session == 'training':
    message.text = f"% korrekte Antworten in diesem Trainingsdurchgang: {accuracy_run: .2f}\n\n\nBitte gib der Versuchsleitung Bescheid!"

message.color = (1, 1, 1)
message.draw()
win.flip()

# wait for 5 s
while ptb.GetSecs() < now + 5:
    core.wait(0.1)

# end experiment by pressing space
end_kb = keyboard.Keyboard(backend = 'ptb')
end_keys = end_kb.waitKeys(keyList=['space'], waitRelease=False)

win.close()
core.quit()

